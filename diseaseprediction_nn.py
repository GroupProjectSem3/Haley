# -*- coding: utf-8 -*-
"""updated_haley.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-IiaCKT0VWyeoxQOWJWcYH_ghKwM7AM7
"""

#if you are not using google collab please ignore this
#to mount google drive
from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.optimizers import SGD

#df = pd.read_csv("/content/drive/My Drive/Group_Project/Binary-200row.csv")
df = pd.read_csv("/content/drive/My Drive/Group_Project/Binary200shuff.csv")

X = np.array(df.iloc[:, df.columns != 'Disease'])
y = np.array(df.iloc[:, df.columns == 'Disease'])

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
#Normalization
from sklearn import preprocessing
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import warnings
warnings.filterwarnings('ignore')
from keras.models import Sequential
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import ShuffleSplit
from sklearn.preprocessing import LabelEncoder
from keras.utils import np_utils
import tensorflow as tf
from keras.models import *
from keras.layers import Dense, Dropout, Activation
from keras.callbacks import *
from sklearn.model_selection import  ShuffleSplit, cross_val_score, cross_val_predict
from sklearn.metrics import confusion_matrix, classification_report

# %matplotlib inline

#train-test split
x_train, x_test, y_train, y_test = train_test_split(X,y,
                                                    test_size=.20,
                                                    random_state=42, stratify = y)

#np.unique([1, 1, 2, 2, 3, 3])
values=np.unique(y_train)
values

Y_train=np.zeros(shape=(len(y_train),len(values)))
k=0
for x in y_train:
     for i in range(len(values)):
            if x==values[i]:
                tmp=list(np.zeros(25))
                tmp[i]=1
                Y_train[k]=tmp
                k+=1

Y_train[1]

model = Sequential()
model.add(Dense(4920, input_dim=100))
model.add(Activation('relu'))
model.add(Dense(2500))
model.add(Activation('relu'))
model.add(Dense(25))
model.add(Activation('sigmoid'))

sgd = SGD(lr=0.1)
model.compile(loss='binary_crossentropy',metrics=['accuracy'], optimizer=sgd)

model.fit(x_train, Y_train, batch_size=1, epochs=3)

model.summary()

#for saving the model
model.save('disease_prediction.h5')  # creates a HDF5 file 'haley_cnn.h5'

#directly use this line in app file and change the path of h5 file accordingly
disease_prediction = tf.keras.models.load_model('/content/disease_prediction.h5')

#np.unique([1, 1, 2, 2, 3, 3])
test_values=np.unique(y_test)
test_values

Y_test=np.zeros(shape=(len(y_test),len(test_values)))
k=0
for x in y_test:
     for i in range(len(test_values)):
            if x==test_values[i]:
                tmp=list(np.zeros(25))
                tmp[i]=1
                Y_test[k]=tmp
                k+=1

indices = [i for i in range(100)] #index of symptoms
symptoms = df.columns.values[:-1]

dictionary = dict(zip(symptoms,indices))#dictionary of all target diseases

#Modified function for displaying top three diseases with probability of occurences
def dosomething(symptom):
    prediction = []
    user_input_symptoms = symptom
    user_input_label = [0 for i in range(100)]
    for i in user_input_symptoms:
        idx = dictionary[i]
        user_input_label[idx] = 1

    user_input_label = np.array(user_input_label)
    user_input_label = user_input_label.reshape((-1,1)).transpose()
    ds = disease_prediction.predict(user_input_label)
    L = np.argsort(-ds, axis=1)
    return(values[L[:,0]],"Percentage:",((ds[0,L[:,0]]*100)),values[L[:,1]],"Percentage:",(ds[0,L[:,1]]*100),values[L[:,2]],"Percentage:",(ds[0,L[:,2]]*100))
    
ds = dosomething(['Sneezing', 'Sore Throat', 'Stuffy Nose' ])
#calculating accuracy on 20% test data
pre=model.predict(x_test)

acc=0;
for i in range(len(pre)):
    if pre[i].argmax() == Y_test[i].argmax() :
        if pre[i].max() >= 0.80:
            acc+=1

acc=acc/len(pre)
acc
